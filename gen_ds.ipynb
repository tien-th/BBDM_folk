{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
      "Restored from /home/PET-CT/vqgan/vq1_3_69.ckpt\n",
      "load vqgan from /home/PET-CT/vqgan/vq1_3_69.ckpt\n"
     ]
    }
   ],
   "source": [
    "from model.BrownianBridge.LatentBrownianBridgeModel import LatentBrownianBridgeModel\n",
    "import yaml\n",
    "import argparse\n",
    "import omegaconf \n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def make_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# ct_path = \"/home/PET-CT/tiennh/test_code/ct\" \n",
    "ct_path = \"/home/PET-CT/splited_data_15k/train/A\"\n",
    "\n",
    "# pet_path = \"/home/PET-CT/tiennh/test_code/ctB\"\n",
    "pet_path = \"/home/PET-CT/splited_data_15k/train/B\"\n",
    "\n",
    "image_size = 256\n",
    "\n",
    "label_fol = \"/home/PET-CT/tiennh/test_code/train/labels\"\n",
    "img_fol = \"/home/PET-CT/tiennh/test_code/train/images\"\n",
    "\n",
    "make_dir(label_fol)\n",
    "make_dir(img_fol)\n",
    "\n",
    "f = open('/home/PET-CT/thaind/BBDM_folk/configs/conditional_LBBDM.yaml', 'r')\n",
    "dict_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "def dict2namespace(config):\n",
    "    namespace = argparse.Namespace()\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, dict) or isinstance(value, omegaconf.dictconfig.DictConfig):\n",
    "            new_value = dict2namespace(value)\n",
    "        else:\n",
    "            new_value = value\n",
    "        setattr(namespace, key, new_value)\n",
    "    return namespace\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "nconfig = dict2namespace(dict_config)\n",
    "ltbbdm = LatentBrownianBridgeModel(nconfig.model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image \n",
    "STATIC_THRESH_HOLD = 100\n",
    "\n",
    "\n",
    "\n",
    "def are_boxes_overlapping(box1, box2):\n",
    "    return not (box2[0] > box1[2] or box2[2] < box1[0] or box2[1] > box1[3] or box2[3] < box1[1])\n",
    "\n",
    "def extract_bb(np_img):\n",
    "    pet_img = np_img.copy() \n",
    "    pet_img = pet_img / 32767. * 255.\n",
    "    pet_img = pet_img.astype(np.uint8)\n",
    "    ret, thresh = cv.threshold(pet_img, STATIC_THRESH_HOLD, 255, 0)\n",
    "\n",
    "    contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    all_bounding_boxes = []\n",
    "\n",
    "    for i in range(len(contours)):\n",
    "        x, y, w, h = cv.boundingRect(contours[i])\n",
    "        # cv.rectangle(all_bounding_boxes_img, (x, y), (x + w, y + h), (0, 0, 0), 1)\n",
    "        all_bounding_boxes.append((x, y, x + w, y + h))\n",
    "    \n",
    "    \n",
    "\n",
    "    sorted_boxes = sorted(all_bounding_boxes, key=lambda box: (box[2] - box[0]) * (box[3] - box[1]), reverse=True)\n",
    "\n",
    "    min_area = 10  # Adjust this value as needed\n",
    "\n",
    "    # Filter out boxes that are too small\n",
    "    filtered_boxes = [box for box in sorted_boxes if (box[2] - box[0]) * (box[3] - box[1]) >= min_area]\n",
    "\n",
    "    # Initialize the list of non-overlapping boxes with the largest one (assuming the largest box is not too small)\n",
    "    non_overlapping_boxes = [filtered_boxes[0]]\n",
    "\n",
    "    # Go through the rest of the boxes and add them if they do not overlap with the existing ones\n",
    "    for current_box in filtered_boxes[1:]:\n",
    "        if all(not are_boxes_overlapping(existing_box, current_box) for existing_box in non_overlapping_boxes):\n",
    "            non_overlapping_boxes.append(current_box)\n",
    "    \n",
    "    return non_overlapping_boxes\n",
    "\n",
    "for file in os.listdir(pet_path):\n",
    "    if file.endswith(\".npy\"):\n",
    "        pet = np.load(os.path.join(pet_path, file), allow_pickle=True)\n",
    "        non_overlapping_boxes = extract_bb(pet) \n",
    "        # Normalize boxes by image size\n",
    "        normalized_boxes = [(x / float(image_size), y / float(image_size), x2 / float(image_size), y2 / float(image_size)) for x, y, x2, y2 in non_overlapping_boxes]\n",
    "        # Save normalized boxes to txt file\n",
    "        for box in normalized_boxes:\n",
    "            with open(os.path.join(label_fol, file[:-4] + \".txt\"), \"a\") as f:\n",
    "                f.write(\"0 \" + \" \".join([str(a) for a in box]) + \"\\n\")\n",
    "        \n",
    "        ct_img = np.load(os.path.join(ct_path, file), allow_pickle=True)\n",
    "        x = ct_img / 2047.\n",
    "        x = Image.fromarray(x)\n",
    "\n",
    "        image = transform(x) \n",
    "        # image = (image - 0.5) * 2.\n",
    "        image = image.unsqueeze(0)\n",
    "\n",
    "        latent = ltbbdm.encode(image)\n",
    "        latent = (latent / 4. + 0.5).clamp(0., 1.)\n",
    "        latent_np = latent.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "        latent_np = latent_np * 255.\n",
    "        latent_np = latent_np.astype(np.uint8)\n",
    "\n",
    "        img = Image.fromarray(latent_np)\n",
    "        # Save numpy image\n",
    "        img.save(os.path.join(img_fol, file[:-4] + \".png\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BBDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
