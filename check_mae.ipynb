{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 295.19282183243786\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "# Define the function to compute MAE\n",
    "def compute_mae(image1, image2):\n",
    "    return np.abs(image1 - image2).mean()\n",
    "\n",
    "# Paths to the folders\n",
    "gt_folder = \"/home/PET-CT/splited_data_15k/train/B\"\n",
    "condition_folder = \"/home/PET-CT/splited_data_15k/train/A\"\n",
    "# pre_folder = \"results/108_CT2PET_UncerBBDM3c/LBBDM-f4/sample_to_eval/200\"\n",
    "\n",
    "dataset_name = 'UncerBBDM_1Unet_confloss_15k_training_samples_top_model'\n",
    "\n",
    "pre_folder = \"/home/PET-CT/thaind/BBDM_folk/results/\" + dataset_name + \"/LBBDM-f4/sample_to_eval/200\"\n",
    "\n",
    "mae_scores = []\n",
    "high_mae, high_mae_gts, high_mae_pds, high_mae_conditions = [], [], [], []\n",
    "\n",
    "# Iterate through the files in the ground truth folder\n",
    "for filename in os.listdir(gt_folder):\n",
    "    # Make sure the file is a numpy array\n",
    "    if filename.endswith(\".npy\"):\n",
    "        # Construct the paths for the corresponding ground truth and predicted files\n",
    "        try:\n",
    "            gt_path = os.path.join(gt_folder, filename)\n",
    "            pre_path = os.path.join(pre_folder, filename)\n",
    "        \n",
    "            # Load the images as numpy arrays\n",
    "            gt_img = np.load(gt_path, allow_pickle=True)\n",
    "            pre_img = np.load(pre_path, allow_pickle=True)\n",
    "        except:\n",
    "            continue   \n",
    "        # Preprocess the predicted image\n",
    "        pre_img1 = pre_img.mean(axis=-1) / 32767.0\n",
    "        \n",
    "        # Normalize the ground truth image\n",
    "        gt_img1 = gt_img / 32767.0\n",
    "\n",
    "        mae = compute_mae(pre_img1, gt_img1)\n",
    "        mae_scores.append(mae * 32767)\n",
    "\n",
    "        if mae * 32767 > 1000  : \n",
    "            high_mae_gts.append(gt_img) \n",
    "            high_mae_pds.append(pre_img)\n",
    "            high_mae_conditions.append(np.load(os.path.join(condition_folder, filename), allow_pickle=True))\n",
    "            high_mae.append(mae * 32767)\n",
    "\n",
    "# Calculate the mean scores over all pairs\n",
    "# mean_ssim = np.mean(ssim_scores)\n",
    "# mean_psnr = np.mean(psnr_scores)\n",
    "mean_mae = np.mean(mae_scores)\n",
    "\n",
    "# Print the mean metrics\n",
    "# print(\"Mean SSIM: {}\".format(mean_ssim))\n",
    "# print(\"Mean PSNR: {}\".format(mean_psnr))\n",
    "print(\"Mean MAE: {}\".format(mean_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_fol(dir_path): \n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 295.19282183243786\n"
     ]
    }
   ],
   "source": [
    "import shutil \n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "# Define the function to compute MAE\n",
    "def compute_mae(image1, image2):\n",
    "    return np.abs(image1 - image2).mean()\n",
    "\n",
    "# Paths to the folders\n",
    "gt_folder = \"/home/PET-CT/splited_data_15k/train/B\"\n",
    "condition_folder = \"/home/PET-CT/splited_data_15k/train/A\"\n",
    "# pre_folder = \"results/108_CT2PET_UncerBBDM3c/LBBDM-f4/sample_to_eval/200\"\n",
    "\n",
    "dataset_name = 'UncerBBDM_1Unet_confloss_15k_training_samples_top_model'\n",
    "\n",
    "pre_folder = \"/home/PET-CT/thaind/BBDM_folk/results/\" + dataset_name + \"/LBBDM-f4/sample_to_eval/200\"\n",
    "\n",
    "mae_scores = []\n",
    "high_mae, high_mae_gts, high_mae_pds, high_mae_conditions = [], [], [], []\n",
    "\n",
    "\n",
    "bad_folder = './baddataset/test'\n",
    "create_fol(bad_folder + '/A') \n",
    "create_fol(bad_folder + '/B')\n",
    "\n",
    "\n",
    "# Iterate through the files in the ground truth folder\n",
    "for filename in os.listdir(gt_folder):\n",
    "    # Make sure the file is a numpy array\n",
    "    if filename.endswith(\".npy\"):\n",
    "        # Construct the paths for the corresponding ground truth and predicted files\n",
    "        try:\n",
    "            gt_path = os.path.join(gt_folder, filename)\n",
    "            pre_path = os.path.join(pre_folder, filename)\n",
    "        \n",
    "            # Load the images as numpy arrays\n",
    "            gt_img = np.load(gt_path, allow_pickle=True)\n",
    "            pre_img = np.load(pre_path, allow_pickle=True)\n",
    "        except:\n",
    "            continue   \n",
    "        # Preprocess the predicted image\n",
    "        pre_img1 = pre_img.mean(axis=-1) / 32767.0\n",
    "        \n",
    "        # Normalize the ground truth image\n",
    "        gt_img1 = gt_img / 32767.0\n",
    "\n",
    "        mae = compute_mae(pre_img1, gt_img1)\n",
    "        mae_scores.append(mae * 32767)\n",
    "\n",
    "        if mae * 32767 > 1000  : \n",
    "            shutil.copy(os.path.join(gt_folder, filename), os.path.join(bad_folder + '/B', filename) )\n",
    "            shutil.copy(os.path.join(condition_folder, filename), os.path.join(bad_folder + '/A', filename) )\n",
    "            \n",
    "            # high_mae_gts.append(gt_img) \n",
    "            # high_mae_pds.append(pre_img)\n",
    "\n",
    "            # high_mae_conditions.append(np.load(os.path.join(condition_folder, filename), allow_pickle=True))\n",
    "            # high_mae.append(mae * 32767)\n",
    "\n",
    "# Calculate the mean scores over all pairs\n",
    "# mean_ssim = np.mean(ssim_scores)\n",
    "# mean_psnr = np.mean(psnr_scores)\n",
    "mean_mae = np.mean(mae_scores)\n",
    "\n",
    "# Print the mean metrics\n",
    "# print(\"Mean SSIM: {}\".format(mean_ssim))\n",
    "# print(\"Mean PSNR: {}\".format(mean_psnr))\n",
    "print(\"Mean MAE: {}\".format(mean_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fol('./baddataset/train/A')\n",
    "create_fol('./baddataset/train/B')\n",
    "create_fol('./baddataset/val/A')\n",
    "create_fol('./baddataset/val/B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe4cfd14730>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "conf_path  = '/home/PET-CT/thaind/BBDM_folk/results/1130_UncerBBDM_1Unet_confloss_15k_alpha_2/LBBDM-f4/sample_to_eval/confidence/13507.npy'\n",
    "np_conf = np.load(conf_path, allow_pickle=True)\n",
    "\n",
    "plt.imshow(np_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.9999944 , 0.9999443 , 0.9998375 ],\n",
       "        [0.9999988 , 0.9999969 , 0.99999845],\n",
       "        [0.99999857, 0.99999785, 0.99999917],\n",
       "        ...,\n",
       "        [0.99999905, 0.9999956 , 0.99999917],\n",
       "        [0.9999994 , 0.9999933 , 0.99999905],\n",
       "        [0.99986136, 0.9999856 , 0.999938  ]],\n",
       "\n",
       "       [[0.99999857, 0.9999629 , 0.9999976 ],\n",
       "        [0.9999995 , 0.99999845, 1.        ],\n",
       "        [0.99999905, 0.99999905, 1.        ],\n",
       "        ...,\n",
       "        [0.99999964, 0.99999833, 1.        ],\n",
       "        [0.9999999 , 0.9999982 , 1.        ],\n",
       "        [0.9999845 , 0.9999975 , 0.9999994 ]],\n",
       "\n",
       "       [[0.99999845, 0.9999721 , 0.99999774],\n",
       "        [0.99999905, 0.9999987 , 1.        ],\n",
       "        [0.99999726, 0.99999845, 1.        ],\n",
       "        ...,\n",
       "        [0.9999987 , 0.999997  , 1.        ],\n",
       "        [0.99999976, 0.9999956 , 1.        ],\n",
       "        [0.99997985, 0.99999464, 0.9999993 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.9999993 , 0.9999794 , 0.99999833],\n",
       "        [0.99999905, 0.99999833, 1.        ],\n",
       "        [0.9999951 , 0.9999981 , 1.        ],\n",
       "        ...,\n",
       "        [0.9999981 , 0.9999976 , 1.        ],\n",
       "        [0.99999976, 0.9999956 , 1.        ],\n",
       "        [0.9999825 , 0.9999963 , 0.9999993 ]],\n",
       "\n",
       "       [[0.99999964, 0.99998415, 0.99999785],\n",
       "        [0.99999964, 0.9999987 , 1.        ],\n",
       "        [0.99999857, 0.9999982 , 1.        ],\n",
       "        ...,\n",
       "        [0.99999917, 0.99999785, 1.        ],\n",
       "        [0.9999999 , 0.99999607, 1.        ],\n",
       "        [0.99998677, 0.9999962 , 0.99999905]],\n",
       "\n",
       "       [[0.9999807 , 0.99978644, 0.99987805],\n",
       "        [0.9999901 , 0.9999745 , 0.99999845],\n",
       "        [0.9999728 , 0.99997044, 0.99999833],\n",
       "        ...,\n",
       "        [0.99997747, 0.9999664 , 0.99999774],\n",
       "        [0.999992  , 0.9999448 , 0.99999785],\n",
       "        [0.99973196, 0.9998472 , 0.99992204]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int,long)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BBDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
